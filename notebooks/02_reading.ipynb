{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data with the `Scene`\n",
    "\n",
    "Satpy's main interface for working with data is the `Scene` class. We can provide the `Scene` with data files and load them with a \"reader\". In this notebook we'll explore the basic data loading and data access functionality provided by Satpy while also providing a basic introduction to xarray's `DataArray` objects and `dask` arrays.\n",
    "\n",
    "Before importing and using Satpy, we run some python code to do some initial setup. This includes turning off warnings and limiting the number of resources we use. These are precautions to make these examples work on the most machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../init_notebook.py\n",
    "from satpy import Scene\n",
    "from glob import glob\n",
    "\n",
    "# Get the list of GOES-16 ABI files to open\n",
    "filenames = glob('../data/abi_l1b/20180511_texas_fire_abi_l1b_conus/*.nc')\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn = Scene(reader='abi_l1b', filenames=filenames)\n",
    "scn.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now created a `Scene` object. Under the hood Satpy has sorted the files and determined what we can access. We haven't actually loaded any data so our dict-like `Scene` object is empty. To find out what data can be loaded from the file we can use the `available_dataset_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn.available_dataset_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Scene` is telling us that we have all 16 ABI channels available to load. This list includes any product that we can load from the file that the \"abi_l1b\" reader is configured to access. If we didn't provide all of the necessary files or the data was missing from the file for some reason, that product would not be listed here.\n",
    "\n",
    "| Channel     | Wavelength  |  Resolution  |\n",
    "| ----------- | ----------- |  ----------- |\n",
    "| C01         | 0.47µm      |  1000m       |\n",
    "| C02         | 0.64µm      |  500m        |\n",
    "| C03         | 0.86µm      |  1000m       |\n",
    "| C04         | 1.37µm      |  2000m       |\n",
    "| C05         | 1.60µm      |  1000m       |\n",
    "| C06         | 2.20µm      |  2000m       |\n",
    "| C07         | 3.90µm      |  2000m       |\n",
    "| C08         | 6.20µm      |  2000m       |\n",
    "| C09         | 6.90µm      |  2000m       |\n",
    "| C10         | 7.30µm      |  2000m       |\n",
    "| C11         | 8.40µm      |  2000m       |\n",
    "| C12         | 9.60µm      |  2000m       |\n",
    "| C13         | 10.30µm     |  2000m       |\n",
    "| C14         | 11.20µm     |  2000m       |\n",
    "| C15         | 12.30µm     |  2000m       |\n",
    "| C16         | 13.30µm     |  2000m       |\n",
    "\n",
    "Let's pick one of these channels, load it, and look what information is provided by Satpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_channel = 'EDITME'\n",
    "scn.load([my_channel])\n",
    "# use brackets to access products like a normal dict\n",
    "scn[my_channel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xarray and Dask\n",
    "\n",
    "Above we see an `xarray.DataArray` object with a lot of metadata.\n",
    "There are a few elements to get familiar with when working with DataArray's from Satpy:\n",
    "\n",
    "* `dask.array<...>`: We don't see any actual imagery data. Our data is stored in a `dask` array instead of a traditional numpy array. This means our data's loading and calculations are delayed.\n",
    "* `Attributes`: A dictionary where the metadata is stored. Some is from the file, some is added by the \"abi_l1b\" reader to assist future Satpy operations. Some of the more important keys are:\n",
    "\n",
    "  * `platform_name`\n",
    "  * `sensor`\n",
    "  * `name`\n",
    "  * `wavelength`\n",
    "  * `units`\n",
    "  * `calibration`\n",
    "  * `standard_name`\n",
    "  * `start_time`\n",
    "  * `area` (more on this later)\n",
    "\n",
    "If we want to access the attributes, we use the `.attrs` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].attrs['start_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the dimension names of the data using the `.dims` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sizes of those dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].sizes['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataArrays also provide us access to traditional numpy properties like `shape` and `ndim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although typically not needed, we can access the dask array underneath xarray's `DataArray` via the `.data` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delayed Calculations\n",
    "\n",
    "It usually isn't necessary to access the dask array directly because xarray will handle all normal arithmetic and numpy functions for us. We can treat the arrays just like normal python variables; adding, subtracting, and storing the result in a new variable.\n",
    "\n",
    "As an arbitrary example, let's add `2.5` to the channel we've loaded and store it in a new variable `my_new_var`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_var = scn[my_channel] + 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataArray` object stored in the `Scene` is unaffected, but our `my_new_var` variable does contain the changes of this calculation. By default, Xarray will keep dimensions and coordinates if it can but lose all attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important point here is how fast these operations seem because of the delayed dask operations involved. We haven't actually done the number crunching yet. Even though we changed the data, we still have a dask array representing those changes. This can sometimes make analyzing our data a little confusing if we're used to plain numpy arrays where normally we might expect immediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these cases we can use the `.compute()` method to load the data and perform the series of calculations that we've built up so far. Dask will split the data across multiple threads to compute values in parallel; handling all of the multithreading and low-level synchronization for us. Let's compute the maximum value of the data stored in the `Scene` and of our new data variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].max().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_var.max().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how this operation still returns a `DataArray` so we will have access to any remaining coordinates or dimensions. If we would like to go back to plain numpy arrays, we can use `.values` to compute the dask array and returning the resulting numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].max().values\n",
    "# we could also do:\n",
    "# scn[my_channel].max().compute().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use them like numpy arrays\n",
    "\n",
    "In most cases, Xarray's `DataArray` objects can be used just like a regular numpy array. When the actual data values are needed they will be computed. This allows us to use `DataArray` objects with other python tools with little to no extra work. Then do a simple matplotlib plot to view our data.\n",
    "\n",
    "<sub>Note: If running on a Jupyter Lab session you may need to change \"notebook\" in the below cell to \"inline\".</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.imshow(scn[my_channel])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use matplotlib calls manually like above, but Xarray also provides its own plotting utility functions to make this easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "scn[my_channel].plot.imshow(cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare the metadata in our DataArray's `.attrs` with what labels are on the plot, we can see where Xarray has made its best guess about what to name components of the plot. It used attributes like `long_name` for the colorbar and the names of the dimensions for the axis labels. Xarray's plotting utilities are simple wrappers around matplotlib so we still have access to everything from matplotlib. We can add common matplotlib function calls like `plt.title(my_channel)` to the above cell, for example, to change the title.\n",
    "\n",
    "We can also change the colormap by passing the `cmap` keyword argument to the call to `imshow` (ex. `cmap='viridis'`). For a full list of the builtin matplotlib colormaps see the [matplotlib documentation](https://matplotlib.org/tutorials/colors/colormaps.html). By default matplotlib will use `viridis` but we can also try others like `plasma`, `magma`, `RdBu_r`, `Reds`, or `tab20b`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing\n",
    "\n",
    "Just like numpy arrays we can slice our `DataArray` to get data for a particular region. We'll use index slicing and striding to show a smaller region and a lower resolution of the channel 2 (`'C02'`) product. Note how slicing does not remove the DataArray attributes. Slicing syntax is `start_index:end_index:stride` where start is inclusive and end is exclusive and stride means taking every X pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load C02 if we haven't already\n",
    "scn.load(['C02'])\n",
    "\n",
    "# slice the DataArray and print out its representation\n",
    "scn['C02'][2500:3500:4, 1500:2500:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()  # create a new figure\n",
    "scn['C02'][2500:3500:4, 1500:2500:4].plot.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "**Time: 5-10 minutes**\n",
    "\n",
    "Using the above examples as a guide, load additional channels, view them with matplotlib, and explore the data either by slicing/striding or by using matplotlib's interactive notebook widget (see toolbar at the bottom left of the image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinate Slicing\n",
    "\n",
    "We can go one step further with the slicing provided by Xarray and slice our DataArray based on coordinates. We'll do more advanced versions of this in later lessons. In the below example we use the X and Y coordinates in meters to slice the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].sel(x=slice(-2650000, -2550000), y=slice(4400000, 4200000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing product variations\n",
    "\n",
    "So far we've been referring to channels by their \"name\". These names are configured in Satpy's readers and can differ between instruments or even generations of the same instrument. Depending on your preferences, you may want to refer to products by wavelength. Not all products have a wavelength associated with them, but for those that do Satpy is configured with a minimum, nominal, and maximum wavelength specification for that instrument. We can use any wavelength within that range to access the data when loading data with the `.load` method or after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].attrs['wavelength']  # in µm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.47 in scn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[0.485].attrs['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets can also vary in a couple other common ways, such as resolution (ex. 1000m versus 500m), calibration (ex. reflectance versus radiance), and polarization (ex. V versus H). We can specify these when identifying products as well using a special `DatasetID` object or with keyword arguments in the `.load` method. To see a full list of the available data products we can use a new method called `Scene.available_dataset_ids`. We'll leave this as an exercise for the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geolocation and Areas\n",
    "\n",
    "Until now we've been dealing with the data as an image with no relation to the Earth. In Satpy, we use a special object in the `.attrs['area']` attribute to define where the data is located.\n",
    "\n",
    "Some people prefer to use longitude and latitude coordinates when working with their data. In these cases we can use the area to get the longitude and latitude data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons, lats = scn[my_channel].attrs['area'].get_lonlats()\n",
    "lons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function can take a while because by default it returns a numpy array. Let's tell it to return a dask array by specifying the `chunks=2048` keyword argument in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(scn[my_channel].attrs['area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].attrs['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"area\" for our ABI data is an `AreaDefinition` object from the `pyresample` library. This means that our data is uniformly gridded on a projected surface. This differs from data that may be non-uniform where the only way to address it is individual longitude and latitude coordinates.\n",
    "\n",
    "We'll learn more about both of these situations in the resampling lesson later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Readers\n",
    "\n",
    "Lastly, let's explore what other readers Satpy current has. We'll use the `available_readers` function to give us a list of useable readers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from satpy import available_readers\n",
    "sorted(available_readers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are missing any of the dependencies for some of Satpy's readers they won't be listed here. We can check what functionality we are missing by using `check_satpy` like we did in the [Introduction](./01_introduction.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
