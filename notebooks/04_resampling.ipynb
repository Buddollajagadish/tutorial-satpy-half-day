{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling\n",
    "\n",
    "One of the more complex topics when it comes to working with earth-observing satellite data is geographic projections and resampling data to these different projections.\n",
    "\n",
    "This is how the book \"Map Projections\" by Battersby describe map projections:\n",
    "\n",
    "> Map projection is the process of transforming angular (spherical / elliptical) coordinates into planar coordinates. All map projections introduce distortion (e.g., to areas, angles, distances) in the resulting planar coordinates. Understanding what, where, and how much distortion is introduced is an important consideration for spatial computations and visual interpretation of spatial patterns, as well as for general aesthetics of any map.\n",
    "\n",
    "<img src=\"http://gistbok.ucgis.org/sites/default/files/figure2-projections.png\" width=\"450px\"/>\n",
    "\n",
    "<sub>Credit: Battersby, S. (2017). Map Projections. The Geographic Information Science & Technology Body of Knowledge (2nd Quarter 2017 Edition), John P. Wilson (ed.). DOI: <a href=\"http://gistbok.ucgis.org/bok-topics/map-projections\">10.22224/gistbok/2017.2.7</a></sub>\n",
    "\n",
    "To simplify projections and resampling for this tutorial, we can think of resampling as mapping data from one projection to another. Projections describe a flat version of our round Earth that is easier to describe. Different people or visualization tools may prefer a certain projection for the data they look at. When comparing data from multiple sources it can be convenient to have them all on the same projection. Let's explore this with real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../init_notebook.py\n",
    "from satpy import Scene\n",
    "from glob import glob\n",
    "\n",
    "filenames = glob('../data/abi_l1b/20180511_texas_fire_abi_l1b_conus/*.nc')\n",
    "scn = Scene(reader='abi_l1b', filenames=filenames)\n",
    "scn.load(['C06'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn['C06'].attrs['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `'area'` attribute of our Satpy data is a special `AreaDefinition` and it defines the geographic area that our data covers. Under `Projection` we see a python dictionary of projection parameters to define that flat plane representation of the Earth. Our ABI data is on a `'geos'` or Geostationary Satellite View coordinate system where position is measured in meters on the the X and Y axes. You can learn more about that on the PROJ site [here](https://proj.org/operations/projections/geos.html). Depending on how we change these parameters we can end up with something like the below view of the Earth or something completely different.\n",
    "\n",
    "<img src=\"https://proj.org/_images/geos.png\" width=\"300\"/>\n",
    "\n",
    "Alternatively, we could read data on a completely different projection like the [Lambert Conformal Conic](https://proj.org/operations/projections/lcc.html) projection and be looking at a view like the image below.\n",
    "\n",
    "<img src=\"https://proj.org/_images/lcc.png\" width=\"300\"/>\n",
    "\n",
    "What projection we have depends on the satellite and who provided our data to us. What projection we want on the output depends on what our end goal is. Do we want to compare our data with another satellite instrument's? Do we want to view our data in a projection that is less distorted for our region of interest?\n",
    "\n",
    "In addition to the geostationary projection information, our `AreaDefinition` specifies an exact location on that projection space: the lower-left corner (in projection meters), the upper-right corner, and the number of row and column pixels.\n",
    "\n",
    "We've already loaded `'C06'`, let's load the `'C05'` channel too and compare them to get a better experience with projections and comparing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn.load(['C05'])\n",
    "scn['C05'].attrs['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn['C06'].attrs['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference in size (rows and columns) between the two area definitions, the small difference in extents, but also how the projection parameters are exactly the same. This is because these two channels are on the same projection (coordinate system), but their individual pixels are different **resolutions**. Each of channel 5's pixels represents 1 kilometer on the geostationary projection and 2 kilometers for each of channel 6's pixels.\n",
    "\n",
    "Trying to compare these with normal array operations would be difficult due to the differences in array shape. Instead we can manipulate and resample the data to allow simpler calculations going forward. We can do this using Satpy's `Scene.resample` method which provides multiple algorithms for resampling data. We'll start by using the very simple `'native'` resampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scn = scn.resample(resampler='native')\n",
    "new_scn['C05'].shape == new_scn['C06'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resample method has given a new `Scene` object with every DataArray we had before, but resampled to the same area or region. By default, it used the highest resolution `AreaDefinition` of the input data (`scn.max_area()`). In this case that's the 1km area from `C05`. If we look at the area of `C06` now we can see it is also at 1km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scn['C06'].attrs['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `native` resampler we used has two possible operations:\n",
    "\n",
    "1. If remapping data to a higher resolution, replicate each pixel to make the shape matches.\n",
    "2. If remapping data to a lower resolution, average/aggregate the pixels to make the shapes match.\n",
    "\n",
    "Now that our two loaded channels have the same shape, we can easily compare them. Let's take the difference between the two channels and plot it. Note that we are using the resampled `new_scn` and **NOT** the original `scn` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "diff = new_scn['C06'] - new_scn['C05']\n",
    "diff.plot.imshow(vmin=-20, vmax=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `native` resampler can be very useful when you need to combine bands from the same instrument that have different resolutions. However, it is limited because it only operates on data on the same projection and with data that can be easily replicated or aggregated (1km -> 2km but not 375m -> 1km).\n",
    "\n",
    "To do more complicated resampling we rely on other resampling algorithms, the simplest being the `nearest` resampler for nearest neighbor resampling. Let's create our own custom AreaDefinition to resample to with our own projection. For this, we'll use Pyresample's `create_area_def` utility function. Running the following cell (with the `?`) will open a new pane with the documentation for the `create_area_def` function. We can use this information to start building a new area to resample to. Feel free to close the pane when you're done using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyresample import create_area_def\n",
    "create_area_def?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_area = create_area_def('my_area', {'proj': 'lcc', 'lon_0': -95, 'lat_0': 25, 'lat_1': 35},\n",
    "                          width=1000, height=1000,\n",
    "                          area_extent=[-105, 20, -90, 40], units='degrees')\n",
    "my_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scn = scn.resample(my_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above AreaDefinition print out that we've created an area using the [Lambert Conformal Conic](https://proj.org/operations/projections/lcc.html) projection that is 1000 rows by 1000 columns. The \"Area extent\" tells us, in the projection space metered coordinates, where our lower left and upper right corners are. We can look at some commmon area properties to get more information on this area we've created, like the resolution of each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_area.pixel_size_x, my_area.pixel_size_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with a 1000x1000 grid of pixels covering this geographic area, we've made it so each pixel represents 1440 meters in the X dimension and 2157 meters in the Y dimension.\n",
    "\n",
    "Let's use Xarray's plotting utilities again to see what this looks like. We'll specify `vmin` and `vmax` to be between 0% and 100% as good initial limits for the colorbar given the traditional limits of reflectance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "new_scn['C05'].plot.imshow(vmin=0, vmax=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in a couple lines of code we've changed the projection, resolution, and overall size of our data. More importantly, our data that started out at different resolutions have been resampled to the same geographic area and resolution so they can be worked with more easily.\n",
    "\n",
    "## Dynamic Areas\n",
    "\n",
    "However, the area we made required us to know the exact region of the Earth we wanted. What if we only knew some of the information and wanted to use our data to fill in the rest. The `create_area_def` function handles this too by creating a `DynamicAreaDefinition` if needed. Let's make a dynamic area where we know the projection and the resolution we want for each pixel (5000 meters). Pay attention to how long each step takes to compute compared to the previous calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dynamic_area = create_area_def('my_area', {'proj': 'lcc', 'lon_0': -95, 'lat_0': 25, 'lat_1': 35},\n",
    "                                  resolution=5000)\n",
    "my_dynamic_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_scn = scn.resample(my_dynamic_area)\n",
    "dynamic_scn['C05'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "dynamic_scn['C05'].plot.imshow(vmin=0, vmax=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you should have noticed is that the call to `resample` took longer than before. This was caused by the calculations necessary to determine how large the resuling area had to be to encompass all of the data.\n",
    "\n",
    "Additionally, the plotting calls should take longer because we are asking for much more data to be resampled and for more data to be plotted. Remember, the dask arrays only load and compute data when it is needed; in this case the area computation and the plotting.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "**Time: 10 minutes**\n",
    "\n",
    "Use the below cells to plot the ABI data on different projections, tweak the projection parameters, or use dynamic areas to resample all of the area. Note how the output changes as projection parameters and area extents change. Projection changes may not be easy to notice on a small scale.\n",
    "\n",
    "Some projection suggestions:\n",
    "\n",
    "1. `{'proj': 'merc', 'lon_0': -97.0}`\n",
    "2. `{'proj': 'lcc', 'lon_0': -95, 'lat_0': 45, 'lat_1': 55, 'lat_2': 65}`\n",
    "3. `{'proj': 'stere', 'lon_0': -105.0, 'lat_ts': 25}`\n",
    "\n",
    "Be careful to not make areas that are too large (many pixels) or you may be waiting a while for processing to finish.\n",
    "\n",
    "If time permits, try loading other channels to the `scn` object (we currently have C05 and C06), changing the extent of the area, trying other matplotlib features, changing the vmin/vmax parameters, or researching other projections. For a full list of supported projections and their options see the [PROJ documentation](https://proj.org/operations/projections/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_area = create_area_def('my_area', {'proj': 'merc', 'lon_0': -97.0},\n",
    "                              width=1000, height=1000,\n",
    "                              area_extent=[-115, 15, -90, 40], units='degrees')\n",
    "custom_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_scn = scn.resample(custom_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "custom_scn['C05'].plot.imshow(vmin=0, vmax=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swaths of Polar-orbiter data\n",
    "\n",
    "So far we've been looking at data from the ABI instrument which is onboard a geostationary satellite. It is common for these type of data to be on a fixed grid or area where all of the pixels are equally spaced. Now we will look at a Polar-orbiter's data; the NOAA-20 (JPSS-01) satellite's VIIRS instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polar_scn = Scene(reader='viirs_sdr', filenames=glob('../data/viirs_sdr/20180511_texas_fire_viirs_sdr/*j01*.h5'))\n",
    "polar_scn.available_dataset_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polar_scn.load(['I04'])\n",
    "polar_scn['I04']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some important differences we can see in the above `I04` band's information compared to the ABI bands we've looked at so far. First, the five `I`, or Imagery resolution, bands on VIIRS have a spatial resolution of about 375m per pixel. The ABI instrument's highest resolution is 500m per pixel and only one channel (C02) is at that resolution, the others at 1km and 2km resolution. The other 16 `M`, or Moderate resolution, bands on VIIRS are 750m resolution. This is one of the major benefits of most polar-orbiting satellites; more bands at higher resolutions. In fact, the VIIRS data provided for this tutorial was limited because of the large size of the datasets.\n",
    "\n",
    "Another key thing to notice about polar-orbiting data is that the `'area'` associated with the data is a new type of object called a `SwathDefinition`. A `SwathDefinition` is a simple container holding on to longitude and latitude arrays. This type of geolocation definition is needed when the pixel spacing of the data is non-uniform and cannot be described by a single \"grid\" of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(polar_scn['I04'].attrs['area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons, lats = polar_scn['I04'].attrs['area'].get_lonlats()\n",
    "lons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this `I04` band to see what it looks like without any resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "polar_scn['I04'].plot.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The edges of this plot look a little strange. This effect is caused by the scanning pattern of the instrument and is known as the \"bow-tie effect\" where pixels from consecutive scans overlap on the edges of the swath. In the case of VIIRS it is also known as \"bow-tie deletion\" because the duplicate pixels from this overlap are actually removed from the data. You may also notice that the plot is flipped horizontally (west coast of Mexico is on the right of the image); a side effect of how the data is observed and how we've plotted it.\n",
    "\n",
    "The most common way to correct these types of effects is to resample the data. Let's reuse the `my_area` definition we created before for ABI, but use it here for VIIRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_polar_scn = polar_scn.resample(my_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "new_polar_scn['I04'].plot.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows one of the downsides of typical polar-orbiter data. Although we have many more bands at a higher resolution, they do not cover a single area very often. The fire in Texas we've been looking at had a majority of its activity and growth in about 4 hours. This VIIRS data from NOAA-20, one of two VIIRS instruments in orbit, was the only pass of the instrument that captured any part of the fire. The ABI instrument however took new images every minute.\n",
    "\n",
    "## Compare ABI and VIIRS\n",
    "\n",
    "Now that we know we can get ABI and VIIRS data on the area, let's do some comparisons. First, we have to load channels or bands that are similar for both instruments. We'll look at the C05 (1.61µm) and C07 (3.90µm) channels from ABI and the I03 (1.61µm) and I04 (3.74µm) channels from VIIRS. The C05 and I03 bands are both reflectance bands (%) and C07 and I04 are brightness temperature bands (K).\n",
    "\n",
    "We should also load data from a similar point in time. Given the temporal resolution of VIIRS data, we'll have to select ABI data from the same time (~20:30Z) as our available VIIRS data. Instead of using the CONUS sector of data we used previously, we'll instead switch to using the smaller Mesoscale sector.\n",
    "\n",
    "We'll recreate all the Scenes and areas to be used for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abi_scn = Scene(reader='abi_l1b', filenames=glob('../data/abi_l1b/20180511_texas_fire_abi_l1b_meso/OR_ABI-L1b-RadM1-M3C??_G16_s20181312030*.nc'))\n",
    "abi_scn.load(['C05', 'C07'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viirs_scn = Scene(reader='viirs_sdr', filenames=glob('../data/viirs_sdr/20180511_texas_fire_viirs_sdr/*j01*t203*.h5'))\n",
    "viirs_scn.load(['I03', 'I04'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the times and size of each band:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ABI: \", abi_scn['C05'].attrs['start_time'])\n",
    "print(abi_scn['C05'].shape)\n",
    "print(abi_scn['C07'].shape)\n",
    "print(\"VIIRS: \", viirs_scn['I03'].attrs['start_time'])\n",
    "print(viirs_scn['I03'].shape)\n",
    "print(viirs_scn['I04'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the two ABI bands have a lower resolution (less pixels) and were observed about 8 seconds after the VIIRS data. Since the ABI data is already gridded to the geostationary (`geos`) projection, let's resample the VIIRS bands to the ABI's area. We'll use the special `max_area` method of the ABI `Scene` to get the highest resolution area of the two loaded channels. We'll also need to resample the ABI channels to be at the same resolution and can use the simple `native` resampler like we did before. Remember that by default the `resample` method will use the `max_area()` of the current Scene.\n",
    "\n",
    "We're also going to use the `dask.persist` function to compute our delayed dask operations up to this point and hold them in memory. This will save us from recomputing these operations in the future, but will use up some of our machine's memory. Normally this isn't needed, but since we might be displaying the data multiple times it would be best to save us from reprocessing it every time. We'll add dask's `ProgressBar` again to get an idea how long each computation is taking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "with ProgressBar():\n",
    "    abi_max_scn = abi_scn.resample(resampler='native')\n",
    "    abi_max_scn['C05'], abi_max_scn['C07'] = dask.persist(abi_max_scn['C05'], abi_max_scn['C07'])\n",
    "\n",
    "    viirs_max_scn = viirs_scn.resample(abi_scn.max_area())\n",
    "    viirs_max_scn['I03'], viirs_max_scn['I04'] = dask.persist(viirs_max_scn['I03'], viirs_max_scn['I04'])\n",
    "\n",
    "print(abi_max_scn['C05'].shape)\n",
    "print(viirs_max_scn['I03'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the printed shapes that our ABI and VIIRS data are the same shape. Now let's plot the 1.61µm band of each Scene (`C05` and `I03`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "abi_max_scn['C05'].plot.imshow(vmin=0, vmax=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "viirs_max_scn['I03'].plot.imshow(vmin=0, vmax=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now put the data from two different instruments on the same gridded region. This will simplify any comparisons or future work we want to do with these data.\n",
    "\n",
    "### Exercise:\n",
    "\n",
    "**Time: 10 minutes**\n",
    "\n",
    "Using the below two cells, plot the differences between the loaded ABI and VIIRS bands using xarray's plotting utilities (one difference plot per cell). Try using the `vmin` and `vmax` keyword arguments and see if limiting colorbar range brings out more information. Keep in mind that Xarray will try to choose the best colormap based on the data. You may want to force the colormap using `cmap='viridis'` or `cmap='RdBu_r'` or try [another colormap](https://matplotlib.org/tutorials/colors/colormaps.html) provided by matplotlib.\n",
    "\n",
    "If time allows try plotting the average (mean) of the two bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C05 - I03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C07 - I04\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution (no cheating): C05 - I03</summary>\n",
    "\n",
    "```\n",
    "plt.figure()\n",
    "diff = abi_max_scn['C05'] - viirs_max_scn['I03']\n",
    "diff.plot.imshow(add_colorbar=True, vmin=-25, vmax=25, cmap='RdBu_r')\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>Solution (no cheating): C07 - I04</summary>\n",
    "\n",
    "```\n",
    "plt.figure()\n",
    "diff = abi_max_scn['C07'] - viirs_max_scn['I04']\n",
    "diff.plot.imshow(add_colorbar=True, cmap='viridis')\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>Solution: (C07 + I04) / 2</summary>\n",
    "\n",
    "```\n",
    "plt.figure()\n",
    "diff = (abi_max_scn['C07'] + viirs_max_scn['I04']) / 2.0\n",
    "diff.plot.imshow(add_colorbar=True, cmap='viridis')\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using resampling we are able to combine arrays that would not normally not be possible. This opens the doors to more types of analysis and the science that can be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping and Aggregating\n",
    "\n",
    "Let's say we didn't want to change projection but only wanted to \"cut out\" a portion of the data or reduce the resolution of our data. Satpy provides the `Scene.crop` and `Scene.aggregate` methods to help us with this.\n",
    "\n",
    "We'll start by using that same ABI Mesoscale Scene we used before. Let's say we wanted to cut out a specific region, but we only knew the longitude and latitude coordinates. By using information from the data's `AreaDefinition` we can use cut out a particular region of the data without having to do any expensive resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abi_scn = Scene(reader='abi_l1b', filenames=glob('../data/abi_l1b/20180511_texas_fire_abi_l1b_meso/OR_ABI-L1b-RadM1-M3C??_G16_s20181312030*.nc'))\n",
    "abi_scn.load(['C05'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_scn = abi_scn.crop(ll_bbox=[-102.0, 34.0, -100.0, 36.0])\n",
    "crop_scn['C05'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "crop_scn['C05'].plot.imshow(cmap='viridis', vmin=0, vmax=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps we wanted to see the whole image, but we didn't need the highest resolution of all of the data. We can use the `Scene.aggregate` method to reduce our overall array size. Here we'll say we want to take the mean (default) of every 8x8 pixels in the `y` and `x` dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_scn = abi_scn.aggregate(y=10, x=10)\n",
    "agg_scn['C05'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "agg_scn['C05'].plot.imshow(vmin=0, vmax=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `aggregate` function takes a couple different possible functions for how it combines the data. Let's say instead of the `mean` we want the `max` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "agg_scn = abi_scn.aggregate(y=10, x=10, func='max')\n",
    "agg_scn['C05'].plot.imshow(vmin=0, vmax=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now finished learning about the `resample`, `crop`, and `aggregate` methods for taking data as provided and manipulating it to be the resolution, size, and region that we wish to analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Research\n",
    "\n",
    " * [Other resampling algorithms][1]\n",
    " * [Caching Resampling][2]\n",
    " * [Store areas for reuse][3]\n",
    " \n",
    "  [1]: https://satpy.readthedocs.io/en/latest/api/satpy.html#module-satpy.resample\n",
    "  [2]: https://satpy.readthedocs.io/en/latest/resample.html#caching-for-geostationary-data\n",
    "  [3]: https://satpy.readthedocs.io/en/latest/resample.html#store-area-definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
